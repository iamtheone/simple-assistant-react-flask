# Lesson 1A: Integrating OpenAI Assistants API

## Overview
In this lesson, we'll enhance our chat application by integrating OpenAI's Assistants API. The Assistants API provides persistent conversation history, code interpretation, and file handling capabilities, making it ideal for sophisticated chat applications.

## Prerequisites
- Completed Lesson 1: Flask and React Setup
- OpenAI API key
- Python 3.8 or higher
- Node.js and npm

## Step 1: Setting Up Dependencies

### 1.1 Update Requirements
Create or update your `requirements.txt`:
```text
flask>=3.0.0
flask-cors>=4.0.0
python-dotenv>=1.0.0
openai>=1.12.0
httpx>=0.26.0
werkzeug>=3.0.0
```

### 1.2 Install Dependencies
```bash
pip install -r requirements.txt
```

## Step 2: Configure Environment

Create a `.env` file in your project root:
```text
OPENAI_API_KEY=your_api_key_here
ASSISTANT_ID=  # This will be populated after creating the assistant
```

## Step 3: Implementing the Assistant

### 3.1 Update Flask Backend
Update `app.py` with the following code:

```python
from flask import Flask, request, Response, stream_with_context
from flask_cors import CORS
from openai import OpenAI
import os
from dotenv import load_dotenv
import time
import json

load_dotenv()

app = Flask(__name__)
CORS(app)

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url="https://api.openai.com/v1"
)

def get_or_create_assistant():
    assistant_id = os.getenv("ASSISTANT_ID")
    
    # If we have an assistant ID, verify it exists
    if assistant_id:
        try:
            client.beta.assistants.retrieve(assistant_id)
            return assistant_id
        except Exception:
            print(f"Could not find assistant with ID: {assistant_id}")
            assistant_id = None
    
    # Create new assistant if needed
    if not assistant_id:
        assistant = client.beta.assistants.create(
            name="Chat Assistant",
            description="A helpful chat assistant that can write code and process files",
            instructions="""You are a helpful and knowledgeable assistant that excels at:
            1. Providing clear and concise responses
            2. Writing and explaining code
            3. Analyzing and processing files
            4. Maintaining context throughout conversations
            Always format code blocks properly and explain your reasoning.""",
            model="gpt-4-turbo-preview",
            tools=[{
                "type": "code_interpreter"
            }],
            temperature=0.7,
            response_format={"type": "text"}
        )
        print(f"Created new assistant with ID: {assistant.id}")
        return assistant.id
    
    return assistant_id

# Initialize assistant
ASSISTANT_ID = get_or_create_assistant()

@app.route("/chat", methods=["POST"])
def chat():
    data = request.json
    message = data.get("message", "")
    thread_id = data.get("thread_id")
    
    try:
        # Create a new thread if none exists
        if not thread_id:
            thread = client.beta.threads.create()
            thread_id = thread.id
        
        # Add message to thread
        client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=message
        )
        
        # Run the assistant
        run = client.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=ASSISTANT_ID
        )
        
        def generate():
            while True:
                # Check run status
                run_status = client.beta.threads.runs.retrieve(
                    thread_id=thread_id,
                    run_id=run.id
                )
                
                if run_status.status == "completed":
                    # Retrieve messages
                    messages = client.beta.threads.messages.list(thread_id=thread_id)
                    latest_message = messages.data[0]
                    if latest_message.role == "assistant":
                        response_data = {
                            "content": latest_message.content[0].text.value,
                            "thread_id": thread_id
                        }
                        yield f"data: {json.dumps(response_data)}\n\n"
                    break
                elif run_status.status == "failed":
                    error_data = {
                        "error": "Assistant run failed",
                        "thread_id": thread_id
                    }
                    yield f"data: {json.dumps(error_data)}\n\n"
                    break
                
                time.sleep(0.5)
        
        return Response(
            stream_with_context(generate()),
            mimetype='text/event-stream'
        )
        
    except Exception as e:
        return {"error": str(e)}, 500

@app.route("/upload", methods=["POST"])
def upload_file():
    if "file" not in request.files:
        return {"error": "No file provided"}, 400
    
    file = request.files["file"]
    
    try:
        # Upload file to OpenAI
        openai_file = client.files.create(
            file=file.stream,
            purpose="assistants"
        )
        
        # Attach file to assistant
        client.beta.assistants.update(
            assistant_id=ASSISTANT_ID,
            file_ids=[openai_file.id]
        )
        
        return {"file_id": openai_file.id}
    except Exception as e:
        return {"error": str(e)}, 500

if __name__ == "__main__":
    app.run(debug=True)
```

## Step 4: Running the Application

1. Start the Flask server:
```bash
python app.py
```

2. When you first run the application, it will create a new assistant and output its ID. Copy this ID and add it to your `.env` file:
```text
ASSISTANT_ID=your_assistant_id_here
```

3. The server will now be running at `http://127.0.0.1:5000`

## Features Implemented

### Assistant Configuration
- GPT-4 Turbo model for better performance
- Code interpreter tool for handling code-related tasks
- Custom instructions for consistent behavior
- Temperature setting for balanced responses

### Conversation Management
- Persistent threads for maintaining context
- Proper message handling and retrieval
- Error handling for failed runs
- File upload support

### API Integration
- Secure API key management
- Proper OpenAI client initialization
- Stream-based response handling
- File attachment capabilities

## Step 5: Testing the Assistant

Let's test our assistant using curl commands. We'll ask it to help us with a programming task and verify that it maintains context between messages.

### 5.1 Initial Request
Send your first message to start a new conversation:
```bash
curl -X POST http://127.0.0.1:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello! Can you help me write a simple Python function to calculate the Fibonacci sequence?"}'
```

Expected response:
```json
data: {"content": "Certainly! The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. That is, the sequence starts 0, 1, 1, 2, 3, 5, 8, 13, 21, and so on....", "thread_id": "thread_xxx"}
```

### 5.2 Follow-up Request
Use the thread_id from the previous response to continue the conversation:
```bash
curl -X POST http://127.0.0.1:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Can you show me how to use these functions with an example?", "thread_id": "thread_xxx"}'
```

Expected response:
```json
data: {"content": "The 10th number in the Fibonacci sequence, calculated using both the recursive and iterative methods, is 34...", "thread_id": "thread_xxx"}
```

### 5.3 What We've Verified
- Assistant creation and initialization ✓
- Message handling and response streaming ✓
- Thread persistence and context maintenance ✓
- Code generation capabilities ✓
- JSON response formatting ✓

## Next Steps
In the next lesson, we'll enhance the UI using ShadCN components to create a modern and responsive chat interface.

## Additional Resources
- [OpenAI Assistants API Documentation](https://platform.openai.com/docs/api-reference/assistants)
- [Flask Documentation](https://flask.palletsprojects.com/)
- [Server-Sent Events (SSE) Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
